import unittest
import unittest.mock
import tempfile
import json
import sys
import os
from unittest.mock import MagicMock

sys.path.append("..") 
from src.sdl.models import LlamaModel
from src.sdl.annotation_io import LlmAnnotationData, LLMAnnotationGenerator


class TestLLMAnnotatorData(unittest.TestCase):
    # mostly generated by LLM
    # TODO: add more edge cases

    def test_constructor(self):
        # Test valid creation
        data = LlmAnnotationData(
            attributes=["Thoughtful", "Detail-oriented"],
            instructions="Annotate with a focus on clarity and completeness.",
            history_ctx_len=5,
            include_moderator_comments=True
        )
        self.assertEqual(data.history_ctx_len, 5)

    def test_from_json_file(self):
        tmp = tempfile.NamedTemporaryFile()
        # Create a sample JSON file
        sample_data = {
            "attributes": ["Analytical", "Concise"],
            "instructions": "Annotate the text focusing on key insights.",
            "history_ctx_len": 4,
        }
        with open(tmp.name, "w") as f:
            json.dump(sample_data, f)

        # Load the data and verify the contents
        data = LlmAnnotationData.from_json_file(tmp.name)
        self.assertEqual(data.attributes, sample_data["attributes"])
        self.assertEqual(data.instructions, sample_data["instructions"])
        self.assertEqual(data.history_ctx_len, sample_data["history_ctx_len"])

    def test_to_json_file(self):
        tmp = tempfile.NamedTemporaryFile()
        # Test serialization to JSON
        data = LlmAnnotationData(
            attributes=["Observant", "Critical"],
            instructions="Provide feedback on argument strength and clarity.",
            history_ctx_len=3,
            include_moderator_comments=True
        )
        data.to_json_file(tmp.name)

        # Verify the content
        with open(tmp.name, "r") as f:
            loaded_data = json.load(f)
        self.assertEqual(loaded_data["attributes"], data.attributes)
        self.assertEqual(loaded_data["instructions"], data.instructions)
        self.assertEqual(loaded_data["history_ctx_len"], data.history_ctx_len)

    def test_missing_required_fields_in_json(self):
        tmp = tempfile.NamedTemporaryFile()
        # Test with missing 'attributes' field in JSON
        incomplete_data = {
            "instructions": "This is a sample instruction."
            # Missing 'attributes' and 'history_ctx_len'
        }
        with open(tmp.name, "w") as f:
            json.dump(incomplete_data, f)

        with self.assertRaises(TypeError):
            LlmAnnotationData.from_json_file(tmp.name)

    def test_invalid_json_structure(self):
        tmp = tempfile.NamedTemporaryFile()
        # Create an invalid JSON file to test error handling
        with open(tmp.name, "w") as f:
            f.write("{invalid_json: true}")

        with self.assertRaises(json.JSONDecodeError):
            LlmAnnotationData.from_json_file(tmp.name)


class TestLLMAnnotationGenerator(unittest.TestCase):

    def setUp(self):
        # Mock LlamaModel to avoid dependencies on actual model logic
        self.mock_llm = MagicMock(spec=LlamaModel)

        # Create sample LLMAnnotatorData for tests
        self.data = LlmAnnotationData(
            attributes=["Insightful", "Direct"],
            instructions="Annotate with focus on logical structure.",
            history_ctx_len=4,
            include_moderator_comments=True
        )
        self.conv_logs_path = "output/conv_logs"

    def test_initialization(self):
        # Initialize generator and verify attributes
        generator = LLMAnnotationGenerator(
            self.data, self.mock_llm, self.conv_logs_path
        )
        self.assertEqual(generator.data, self.data)
        self.assertEqual(generator.llm, self.mock_llm)
        self.assertEqual(generator.conv_logs_path, self.conv_logs_path)

    def test_produce_conversation(self):
        # Mock the AnnotationConv class to isolate `produce_conversation` behavior
        with unittest.mock.patch("src.sdl.annotation.AnnotationConv") as MockAnnotationConv:
            #TODO: investigate this test
            generator = LLMAnnotationGenerator(
                self.data, self.mock_llm, self.conv_logs_path
            )
            conversation = generator.produce_conversation()

            # Check if the correct parameters were passed to create AnnotationConv
            MockAnnotationConv.assert_called_once_with(
                annotator=unittest.mock.ANY,  # Placeholder for the LLMAnnotator instance
                conv_logs_path=self.conv_logs_path,
                history_ctx_len=self.data.history_ctx_len,
            )

    def test_produce_conversation_with_invalid_data(self):
        # Test if initialization fails with an invalid model
        with self.assertRaises(Exception):
            LLMAnnotationGenerator(None, None, self.conv_logs_path) # type: ignore


if __name__ == "__main__":
    unittest.main()
