import unittest
import sys
import json
import os

sys.path.append("..") 
from src.sdl.conversation_io import LLMConvData


class TestLLMConvData(unittest.TestCase):
    # mostly generated by LLM
    # TODO: add more edge cases

    def test_constructor_assertions(self):
        # Test invalid cases with mismatched user names and attributes
        with self.assertRaises(AssertionError):
            LLMConvData(
                context="Test context",
                user_names=["Steve2001", "GeorgeBush78"],
                user_attributes=[["African American"]],
                user_instructions="Sample instructions",
                turn_manager_type="round robin"
            )
        
        # Test valid case where user names and attributes are matched
        data = LLMConvData(
            context="Sample context",
            user_names=["User1", "User2"],
            user_attributes=[["Attribute1"], ["Attribute2"]],
            user_instructions="Sample user instructions",
            turn_manager_type="round robin"
        )
        self.assertEqual(len(data.user_names), len(data.user_attributes))

    def test_optional_fields(self):
        # Test creation with and without optional fields
        data_with_moderator = LLMConvData(
            context="Sample context",
            user_names=["User1", "User2"],
            user_attributes=[["Attribute1"], ["Attribute2"]],
            user_instructions="User instructions",
            turn_manager_type="round robin",
            moderator_name="Moderator1",
            moderator_attributes=["Firm", "Calm"],
            moderator_instructions="Sample moderator instructions"
        )
        self.assertIsNotNone(data_with_moderator.moderator_name)
        self.assertIsNotNone(data_with_moderator.moderator_attributes)
        
        # Case without optional fields
        data_without_moderator = LLMConvData(
            context="Sample context",
            user_names=["User1", "User2"],
            user_attributes=[["Attribute1"], ["Attribute2"]],
            user_instructions="User instructions",
            turn_manager_type="round robin"
        )
        self.assertIsNone(data_without_moderator.moderator_name)
        self.assertIsNone(data_without_moderator.moderator_attributes)

    def test_from_json_file(self):
        # Create a sample JSON file to test deserialization
        sample_data = {
            "context": "Test context",
            "user_names": ["User1", "User2"],
            "user_attributes": [["Attr1"], ["Attr2"]],
            "user_instructions": "Test instructions",
            "turn_manager_type": "round robin"
        }
        with open("output/test.json", "w") as f:
            json.dump(sample_data, f)

        # Test loading the JSON file
        data = LLMConvData.from_json_file("output/test.json")
        self.assertEqual(data.context, sample_data["context"])
        self.assertEqual(data.user_names, sample_data["user_names"])
        
        # Clean up
        os.remove("output/test.json")

    def test_to_json_file(self):
        # Create an LLMConvData instance and serialize it
        data = LLMConvData(
            context="Test context for serialization",
            user_names=["User1", "User2"],
            user_attributes=[["Attr1"], ["Attr2"]],
            user_instructions="User instructions",
            turn_manager_type="round robin"
        )
        data.to_json_file("output/test_to_json.json")

        # Reload the JSON file and check the content
        with open("output/test_to_json.json", "r") as f:
            loaded_data = json.load(f)
        self.assertEqual(loaded_data["context"], data.context)
        self.assertEqual(loaded_data["user_names"], data.user_names)

        # Clean up
        os.remove("output/test_to_json.json")

    def test_invalid_json_structure(self):
        # Create an invalid JSON file to test error handling
        with open("output/test_invalid.json", "w") as f:
            f.write("{invalid_json: true}")

        with self.assertRaises(json.JSONDecodeError):
            LLMConvData.from_json_file("output/test_invalid.json")

        # Clean up
        os.remove("output/test_invalid.json")

    def test_missing_required_fields(self):
        # Test case with missing required fields in JSON data
        incomplete_data = {
            "context": "Incomplete data",
            "user_names": ["User1"],
            # Missing 'user_attributes' and 'user_instructions'
        }
        with open("output/test_incomplete.json", "w") as f:
            json.dump(incomplete_data, f)

        with self.assertRaises(TypeError):
            LLMConvData.from_json_file("output/test_incomplete.json")

        # Clean up
        os.remove("output/test_incomplete.json")


if __name__ == "__main__":
    unittest.main()
